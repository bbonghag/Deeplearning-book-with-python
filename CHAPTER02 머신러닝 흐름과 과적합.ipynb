{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMtVfnpAr4AYc/gsqAHMO5L"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# CHAPTER2 머신러닝 흐름과 과적합"],"metadata":{"id":"D7ChTk1xBI7_"}},{"cell_type":"markdown","source":["## 2.1 머신러닝의 흐름"],"metadata":{"id":"rf1qAbXPBKbG"}},{"cell_type":"markdown","source":["### 2.1.1 지도학습의 흐름\n","\n","1. 데이터 수집\n","2. 데이터 클렌징\n","3. 머신러닝 기법으로 데이터 학습(기준 취득)\n","4. 테스트 데이터로 성능 테스트\n","5. 머신러닝 모델을 웹환경 등에서 구현\n","\n","=⇒ 머신러닝 실행에는 사전 준비(데이터 수집 및 전처리) 및 결과의 고찰이 필요."],"metadata":{"id":"h5PPeb24BOD2"}},{"cell_type":"markdown","source":["### 2.1.2 데이터 학습\n","\n","> 아이리스 데이터를 산포도로 그리고 선을 그어 구분하려면?\n","\n","- 사람은 보고 두 데이터를 구분짓는 선을 그으면 된다\n","- 컴퓨터가 분류하도록 시키는 건 쉽지 않다\n","- 어떻게 하면 컴퓨터가 분류할 수 있게 될까??\n","  \n","  1. 적당한 선 긋기\n","  \n","  2. 그은 선이 적절한 위치에 있는지 계산하기\n","\n","  3. 선 위치를 개선하여 수정하기\n","\n","  4. 점을 적절히 분류할 수 있는 위치에 선을 그리면 종료\n","\n","- 2번, 3번을 반복하면 정확한 선을 그릴 수 있게 된다\n","- 컴퓨터 스스로 답을 찾아 데이터의 패턴으로 만든 기준을 **모델**이라 한다\n","\n","\n","=> 지도학습은 데이터 중에서 패턴을 찾고, 분류하기 위한 모델을 만든다"],"metadata":{"id":"vG__F_dKBQp8"}},{"cell_type":"markdown","source":["## 2.2 학습 데이터 사용법"],"metadata":{"id":"h-Du0VfgC7oc"}},{"cell_type":"markdown","source":["### 2.2.1 훈련 데이터와 테스트 데이터\n","\n","- 훈련 데이터 : 학습에 사용하는 데이터\n","- 테스트 데이터 : 학습된 모델의 정밀도를 평가할 때 사용하는 데이터\n","- 왜 훈련, 테스트 데이터로 나누는가?? => 머신러닝이 미지의 데이터를 예측하는 것이 목적이기 때문\n","\n","=> 따라서 머신러닝 모델 평가에는 학습에 사용되지 않는 테스트 데이터를 사용한다"],"metadata":{"id":"qNS9APAzC9vX"}},{"cell_type":"markdown","source":["### 2.2.2 홀드아웃 방법의 이론과 실현\n","\n","- 데이터 분리하는 방법\n","\n","  1. 홀드아웃 방법 : 데이터셋을 훈련, 테스트 2개로 분할\n","\n","  ```\n","  X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=41)\n","  ```\n","\n","  2. K-분할 교차검증\n","\n","\n","\n","\n","\n"],"metadata":{"id":"0ycSjQ3YDZ8L"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y1LpVkQm4OOQ","executionInfo":{"status":"ok","timestamp":1667790786908,"user_tz":-540,"elapsed":306,"user":{"displayName":"두루미","userId":"06775262425078058900"}},"outputId":"371fa7bb-d408-4130-9ad1-7e38eb849593"},"outputs":[{"output_type":"stream","name":"stdout","text":["X_train:  (120, 4)\n","y_train:  (120,)\n","X_test:  (30, 4)\n","y_test:  (30,)\n"]}],"source":["from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","\n","iris = datasets.load_iris()\n","X = iris.data \n","y = iris.target\n","\n","X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=41)\n","\n","print('X_train: ', X_train.shape)\n","print('y_train: ', y_train.shape)\n","print('X_test: ', X_test.shape)\n","print('y_test: ', y_test.shape)"]},{"cell_type":"markdown","source":["### 2.2.3 k-분할 교차검증의 이론\n","- 모델 평가 검증의 하나로 비복원 추출을 통해 훈련 데이터셋을 k개로 분할하고 k-1개의 데이터는 학습 데이터셋, 나머지 1개는 테스트 데이터셋으로 사용하는 방법\n","- k개의 모델과 그 모델에 대한 성능 평가를 k개 얻을 수 있기에 k회 학습과 평가를 반복하고 k개 성능 평가의 평균을 취해 평균 성능을 산출한다\n","---\n","- 보다 안정되고 정확한 모델 평가가 가능\n","- 하지만 k회의 학습과 평가를 하기에 k배 연산이 필요하여 오래 걸린다는 단점 존재\n","- 일반적으로 k값을 5~10 사용한다"],"metadata":{"id":"tAvVGf4pE_Xo"}},{"cell_type":"markdown","source":["### 2.2.4 k-분할 교차검증의 실현\n","\n","사이킷런 공식 설명 참고 : https://scikit-learn.org/stable/modules/cross_validation.html"],"metadata":{"id":"v1Q1n4ymF_F6"}},{"cell_type":"code","source":["from sklearn import svm, datasets\n","from sklearn.model_selection import cross_val_score\n","\n","iris = datasets.load_iris()\n","X = iris.data\n","y = iris.target\n","\n","svc = svm.SVC(C=1, kernel='rbf', gamma=0.001)\n","\n","scores = cross_val_score(svc, X, y, cv=5)\n","\n","print(scores)\n","print('평균 점수 : ', scores.mean())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jyBjY43UD-vM","executionInfo":{"status":"ok","timestamp":1667791266189,"user_tz":-540,"elapsed":445,"user":{"displayName":"두루미","userId":"06775262425078058900"}},"outputId":"ceb10f75-dc60-4dd3-c87d-1e5a619a7f71"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.86666667 0.96666667 0.83333333 0.96666667 0.93333333]\n","평균 점수 :  0.9133333333333334\n"]}]},{"cell_type":"markdown","source":["## 2.3 과적합\n","\n","- 주어진 데이터에 과하게 적용되어 올바른 기준을 구축하지 못한 것, 컴퓨터가 데이터를 과하게 학습한 상태\n","\n","![ㅇ](https://img1.daumcdn.net/thumb/R1200x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb9JaJx%2FbtqLNrFkfqL%2FFLuUqxJikQZ56RNCoRXPgk%2Fimg.jpg)"],"metadata":{"id":"1un7PivWHHuv"}},{"cell_type":"markdown","source":["### 2.3.1 과적합의 회피\n","\n","- 드랍아웃 : 학습 시 일부 뉴런을 없애는 방법\n","- 정규화 : 편향된 데이터의 영향을 없애는 방법\n","---\n","=> 컴퓨터가 데이터를 과도하게 학습한 상태를 과적합이라 부르며 / 데이터를 제대로 학습하지 못한 상태를 과소적합이라 한다\n","\n","=> 과적합을 일으키고 있는 모델은 분산이 크고 / 과소적합을 일으키고 있는 모델은 편향이 크다"],"metadata":{"id":"jMUCNRoyHZQI"}},{"cell_type":"markdown","source":["## 2.4 앙상블 학습\n","- 여러 모델을 학습시킴으로 데이터의 일반화 획득\n","  \n","  1. 배깅 : 복수 모델을 동시에 학습시켜 예측 결과의 평균을 취해 예측 결과의 일반화\n","\n","  2. 부스팅 : 모델의 예측 결과에 대한 모델을 만들어 일반화 성능을 높인다"],"metadata":{"id":"gGSjThsCTqEi"}},{"cell_type":"code","source":[],"metadata":{"id":"wpCUz4nTD-sz"},"execution_count":null,"outputs":[]}]}