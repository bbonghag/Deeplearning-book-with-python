{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPzUTTOyQzFClgG5j/hoo+G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# CHAPTER20 딥러닝 튜닝"],"metadata":{"id":"xG0eKRDLSHjq"}},{"cell_type":"markdown","source":["## 20.1 하이퍼파라미터\n","\n","- 네트워크를 구성시 사람이 조정해야하는 파라미터"],"metadata":{"id":"F4ySlJ1iSTJO"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hxos8WriSDeu"},"outputs":[],"source":["import numpy as np \n","import matplotlib.pyplot as plt\n","from keras.datasets import mnist\n","from tensorflow import keras\n","from keras import layers\n","from keras.layers import Activation, Dense, Dropout\n","from keras.models import Sequential, load_model\n","from keras import optimizers\n","from keras.utils.np_utils import to_categorical\n","\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","X_train = X_train.reshape(X_train.shape[0], 784)[:6000]\n","X_test = X_test.reshape(X_test.shape[0], 784)[:1000]\n","y_train = to_categorical(y_train)[:6000]\n","y_test = to_categorical(y_test)[:1000]\n","\n","model = Sequential([\n","    layers.Dense(256, input_dim=784, activation='sigmoid'), # 하이퍼파라미터 : 은닉층수(은닉층의 채널수), 활성화 함수\n","    layers.Dense(128, activation='sigmoid'),\n","    layers.Dropout(0.5), # 하이퍼파라미터 : 드롭아웃 비율\n","    layers.Dense(10, activation='softmax')\n","])\n","\n","sgd = keras.optimizers.SGD(learning_rate=0.1) # 하이퍼파라미터 : 학습률\n","model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy']) # 하이퍼파라미터 : 옵티마이저, 로스\n","\n","history = model.fit(X_train, y_train, batch_size=500, epochs=5, verbose=1, validation_data=(X_test, y_test)) # 하이퍼파라미터 : 배치 사이즈, epoch수\n","\n","plt.plot(history.history['accuracy'], label='acc', ls='-', marker='o')\n","plt.plot(history.history['val_accuracy'], label='val_acc', ls='-', marker='x')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(loc='best')\n","plt.show()"]},{"cell_type":"markdown","source":["## 20.2 네트워크 구조\n","\n","- 네트워크 구조(은닉층 수, 은닉층의 유닛 수)는 자유롭게 설정 가능\n","- 층이나 유닛수가 너무 많거나 적으면 원활한 학습이 힘들기에 적절한 수로 조정하는 것이 중요하다"],"metadata":{"id":"kP6S8Sr3TIzz"}},{"cell_type":"code","source":["import numpy as np \n","import matplotlib.pyplot as plt\n","from keras.datasets import mnist\n","from tensorflow import keras\n","from keras import layers\n","from keras.layers import Activation, Dense, Dropout\n","from keras.models import Sequential, load_model\n","from keras import optimizers\n","from keras.utils.np_utils import to_categorical\n","\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","X_train = X_train.reshape(X_train.shape[0], 784)[:6000]\n","X_test = X_test.reshape(X_test.shape[0], 784)[:1000]\n","y_train = to_categorical(y_train)[:6000]\n","y_test = to_categorical(y_test)[:1000]\n","\n","model = Sequential()\n","model.add(layers.Dense(256, input_dim=784))\n","model.add(layers.Activation('sigmoid'))\n","\n","def funcA():\n","    model.add(Dense(128))\n","    model.add(Activation('sigmoid'))\n","\n","def funcB():\n","    model.add(Dense(128))\n","    model.add(Activation('sigmoid'))\n","    model.add(Dense(128))\n","    model.add(Activation('sigmoid'))\n","    model.add(Dense(128))\n","    model.add(Activation('sigmoid'))\n","\n","def funcC():\n","    model.add(Dense(1568))\n","    model.add(Activation('sigmoid'))\n","\n","funcA()\n","# funcB()\n","# funcC()\n","\n","model.add(Dense(10, activation='softmax'))\n","\n","sgd = keras.optimizers.SGD(learning_rate=0.1) \n","model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy']) \n","\n","history = model.fit(X_train, y_train, batch_size=32, epochs=5, verbose=1) \n","\n","loss, acc = model.evaluate(X_test, y_test)\n","print(f'loss : {loss} \\nacc : {acc}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xuvm7118S_xy","executionInfo":{"status":"ok","timestamp":1669187347868,"user_tz":-540,"elapsed":10699,"user":{"displayName":"두루미","userId":"06775262425078058900"}},"outputId":"995a89af-84e4-4c98-f459-382d39c34a05"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n","Epoch 1/5\n","188/188 [==============================] - 1s 4ms/step - loss: 1.3686 - accuracy: 0.6393\n","Epoch 2/5\n","188/188 [==============================] - 1s 4ms/step - loss: 0.7001 - accuracy: 0.8322\n","Epoch 3/5\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5578 - accuracy: 0.8675\n","Epoch 4/5\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5190 - accuracy: 0.8672\n","Epoch 5/5\n","188/188 [==============================] - 2s 8ms/step - loss: 0.5003 - accuracy: 0.8630\n","32/32 [==============================] - 0s 3ms/step - loss: 0.5684 - accuracy: 0.8340\n","loss : 0.568393349647522 \n","acc : 0.8339999914169312\n"]}]},{"cell_type":"markdown","source":["## 20.3 드롭아웃\n","\n","- 과적합을 방지하고 모델의 정확도를 높이는 방법 중 하나\n","- 드롭아웃을 적용하면 유닛의 일부가 학습할때마다 무작위로 0으로 적용됨 -> 학습x"],"metadata":{"id":"v-wyR7M5UcUU"}},{"cell_type":"code","source":["(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","X_train = X_train.reshape(X_train.shape[0], 784)[:6000]\n","X_test = X_test.reshape(X_test.shape[0], 784)[:1000]\n","y_train = to_categorical(y_train)[:6000]\n","y_test = to_categorical(y_test)[:1000]\n","\n","model = Sequential()\n","model.add(Dense(256, input_dim=784))\n","model.add(Activation('sigmoid'))\n","model.add(Dense(128, activation='sigmoid'))\n","################################### 드롭아웃 코드 작성 ########################\n","model.add(Dropout(0.5))\n","################################### 드롭아웃 코드 작성 ########################\n","model.add(Dense(10, activation='softmax'))\n","\n","sgd = keras.optimizers.SGD(learning_rate=0.1) \n","model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy']) \n","\n","history = model.fit(X_train, y_train, batch_size=500, epochs=5, verbose=1, validation_data=(X_test, y_test)) # 하이퍼파라미터 : 배치 사이즈, epoch수\n","\n","plt.plot(history.history['accuracy'], label='acc', ls='-', marker='o')\n","plt.plot(history.history['val_accuracy'], label='val_acc', ls='-', marker='x')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(loc='best')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":461},"id":"qLd-9sbtS_lA","executionInfo":{"status":"ok","timestamp":1669187527836,"user_tz":-540,"elapsed":7336,"user":{"displayName":"두루미","userId":"06775262425078058900"}},"outputId":"893eba97-3d59-4be0-d763-4eda566f3ebd"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","12/12 [==============================] - 2s 77ms/step - loss: 2.4426 - accuracy: 0.1442 - val_loss: 2.0594 - val_accuracy: 0.4800\n","Epoch 2/5\n","12/12 [==============================] - 1s 51ms/step - loss: 2.1098 - accuracy: 0.2558 - val_loss: 1.8519 - val_accuracy: 0.6410\n","Epoch 3/5\n","12/12 [==============================] - 1s 41ms/step - loss: 1.8761 - accuracy: 0.3708 - val_loss: 1.6706 - val_accuracy: 0.6830\n","Epoch 4/5\n","12/12 [==============================] - 0s 34ms/step - loss: 1.6852 - accuracy: 0.4727 - val_loss: 1.5006 - val_accuracy: 0.7190\n","Epoch 5/5\n","12/12 [==============================] - 0s 35ms/step - loss: 1.5267 - accuracy: 0.5500 - val_loss: 1.3622 - val_accuracy: 0.7450\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5dn/8c+VjSQQEkhYshASFtkRMCICAqIWFAVcKLhVa4Vq3f2Vp2pt8VGfp7Z000pRHsV9V6CoKJW9iAsgaFglECALEAgkJJB1cv/+OJNkEhKYQCZnluv9evFizpl7MlcOzP09c59z7iPGGJRSSgWuILsLUEopZS8NAqWUCnAaBEopFeA0CJRSKsBpECilVIALsbuApoqLizMpKSl2l6GUUj5l48aNR4wxHRp6zueCICUlhQ0bNthdhlJK+RQR2dfYczo0pJRSAU6DQCmlApwGgVJKBTifO0bQkIqKCrKzsyktLbW7FK8UHh5OUlISoaGhdpeilPJCfhEE2dnZREVFkZKSgojYXY5XMcaQn59PdnY2qampdpejlPJCfjE0VFpaSmxsrIZAA0SE2NhY/baklK9a+3fIXFN3XeYaa30z8YsgADQETkO3jVI+LHEIfHB7bRhkrrGWE4c021v4xdCQUkr5nbJiOJ4DjgoYdBO8/VMYMAV2fApTXoXUUc32VhoESinV0spPwvFcOJ4NhTn1HudYf5cVnvq6716HUf/VrCEAARoEizblMHvpTnILSkiIiWDmuF5MHpxod1lKKX9QWVbbmR/Pqfu4MMfq8EuOnfq6yDhomwDtUqDrCIhOhLbOP8dz4PNHIO0XsOFlSL1EvxGci0Wbcnh0QTolFQ4AcgpKeHRBOsA5h8HkyZPJysqitLSUBx54gBkzZvD555/z2GOP4XA4iIuLY/ny5RQXF3PfffexYcMGRIRZs2Zx/fXXn/PvppTyMEeFc+/duRdfmF23gz+eCycOn/q6iHa1nXqXC2sfu3b2oeENv2fmGisEqoeDUi+xjhE04/CQ3wXBf3+8lW25xxt9ftP+AsodVXXWlVQ4+K8Pf+Cdb/c3+Jq+CW2ZdU2/M773/Pnzad++PSUlJVx44YVMmjSJ6dOns2bNGlJTUzl69CgATz31FNHR0aSnWwF07FgDewdKqZblqITigw3sybsM3xQfAurd3rdVtLUnH50I8YMgOslabptY+zis9dnXlfNd3U4/dZS1nPOdBsHZqh8CZ1rfFM899xwLFy4EICsri3nz5jFq1Kia8/fbt28PwLJly3j33XdrXteuXbtzfm+l1GlUOaA4r4GhmuzavfuiA2Dq9QOhrWv32jv1hbZJtZ1+9ePwtp6tfeSDp65LHaVDQ6dzpj33Ec+sIKeg5JT1iTERvPfLi8/6fVetWsWyZcv46quviIyMZMyYMQwaNIgdO3ac9c9USrmhqgpOHnF26rl1O/jqPfmiXKiqrPu6kPDa4ZnU0c7OPcHq4Ks7//BoCIDTr/0uCM5k5rhedY4RAESEBjNzXK9z+rmFhYW0a9eOyMhIduzYwddff01paSlr1qwhMzOzZmioffv2XHHFFcyZM4e//926IOTYsWP6rUAFjrV/t86Bd92jzVxjDXXU3/s1Bk4erR1/r9/BV693lNd9XXBYbafe9WLnOHyCc6jGOWQT0S4gOnl3BFwQVB8Qbu6zhsaPH88LL7xAnz596NWrF8OGDaNDhw7MmzeP6667jqqqKjp27MgXX3zB448/zj333EP//v0JDg5m1qxZXHfddc3x6ynl/aovkLrhFYgfCNsWw79/C4NvheVP1Ru+yYXKet/gg0Igyjk8k5gGfVw7eOeQTWQsBPnN9bIeJ8aYM7fyImlpaab+jWm2b99Onz59bKrIN+g2UrapKIWju+HIj3Akw/o7ZyMc3cMpB14lCKLiTz2jprqDj06E1h0gKNiWX8WXichGY0xaQ88F3DcCpZQHGAMnjjg7+x8hP6P28bF91Onwo7tAXE9r/D33O+gzEYbfZ3X4bTpBsHZLLU23uFLKfY4KOLbX2cnvcv5xdvilBbXtQsIhtickDIGB06yOP+48iO1unUpZPV/OqP+yLpAaOt3a21e20CBQSp2qpKC2k8936fCP7ql79k2bTlYH3/866+/qDr9tUuNj9NUh4MELpFTTeDQIRGQ88CwQDLxkjHmm3vN/Ay51LkYCHY0xMZ6sSSnlVOWAwqx6e/bOv0/k1bYLCoX23awOvvfVtR1+bA+IOIuPawtcIKWaxmNBICLBwBzgCiAbWC8ii40x26rbGGMecml/HzDYU/UoFbDKT1gdvOu4ffVypct9KsJjoEMvOO8nzs7+PGt4p11XCG7Gu9u1wAVSqmk8+Y1gKJBhjNkDICLvApOAbY20vxGY5cF6lPJfxlhXxp4ydr/LOte+mgRBTFerk+82prbDj+tpnXKp59UHJE8GQSKQ5bKcDVzUUEMR6QqkAisaeX4GMAMgOTm5eatUypdUlkH+7lPH7o/sgvLi2nZhbazOPWWEy4HantYQT2OTm6mA5S0Hi6cBHxpjHA09aYyZB8wD6zqCc3qnplzV6CFt2rShuLj4zA1VYDIGTubXHbOv/rtgX935cNomWR39oJudHb6z04+K17175TZPBkEO0MVlOcm5riHTgHs8WEut6qsaqw9WuZ7BoFRLclRap2Lm76o7dn/kx7rz1YeEWwdmEwbBwJ9ae/bVB2tbtbGtfOU/PBkE64GeIpKKFQDTgJvqNxKR3kA74KtmedfPHoGD6advExUPb1xr/V10ADr0hlV/tP40pPMAuPKZhp8DHnnkEbp06cI991hZ9sQTTxASEsLKlSs5duwYFRUVPP3000yaNOmM5RcXFzNp0qQGX/f666/z5z//GRFh4MCBvPHGGxw6dIi77rqLPXv2ADB37lyGDx9+xvdRzcSdb5ilhbVX1Lp2+Ef3QFVF7etad7T25vtOdjkVs6d1AZZeSas8yGNBYIypFJF7gaVYp4/ON8ZsFZEngQ3GmMXOptOAd01LznURHmOFQGGW9SELP7czVqdOncqDDz5YEwTvv/8+S5cu5f7776dt27YcOXKEYcOGMXHixDPeSD48PJyFCxee8rpt27bx9NNPs27dOuLi4mrubXD//fczevRoFi5ciMPh0CGnluY6b077VNjyEayebQXDq1dbnX7xodr2QSEup2JeVTt2H9fDmgRNKRt49BiBMWYJsKTeut/XW36iWd/0NHvuNepf1TjmN+d06trgwYPJy8sjNzeXw4cP065dOzp37sxDDz3EmjVrCAoKIicnh0OHDtG5c+fT/ixjDI899tgpr1uxYgVTpkwhLi4OqL23wYoVK3j99dcBCA4OJjo6+qx/D+WmsmLI2w6H0uHQVmtP/vVJ1JlGYf86iOsFPa6oO3bfLqV5T8VUqhl4y8HiluOhqxqnTJnChx9+yMGDB5k6dSpvvfUWhw8fZuPGjYSGhpKSkkJpaekZf87Zvk55gDHWwdmDW6wOv7rjP5pJTaffqi106meN3+dugvNvhCuegtZxerBW+YzACwIPXdU4depUpk+fzpEjR1i9ejXvv/8+HTt2JDQ0lJUrV7Jv3z63fk5hYWGDrxs7dizXXnstDz/8MLGxsTX3NrjsssuYO3cuDz74YM3QkH4rOAtlxZC3DQ5tcen4t0J5kbOBWEM6nfpbnX2nftbjmGTY+5+63zAH3QRt9OIo5TsCLwg8dFVjv379KCoqIjExkfj4eG6++WauueYaBgwYQFpaGr1793br5zT2un79+vHb3/6W0aNHExwczODBg3n11Vd59tlnmTFjBi+//DLBwcHMnTuXiy8++zut+b2qKmsv/9BWq9Ov7viPZda2qd7LP3+a9XfnAdYJBQ2doaPz5ig/oPcjCBABuY3Kiqyx/IPpLh3/tlP38jv3t/buO/W3Ov6YZPeHdbzguhSl3KH3I1D+raoKCvbWDudUd/x19vKja/fyqzv+jn2sKZHPhc6bo/yABoFN0tPTufXWW+usa9WqFd98841NFfmIsiJrr776wO3BLdbYfs30CmLNeR9/vnW1bWfnXn50Fz14q1Qj/CYIjDFnPEffmwwYMIDNmze3yHv52vAfULuXX3Pg1jmef2xvbZtW0VZHP+im2qGdjn0gLNKuqpXySX4RBOHh4eTn5xMbG+tTYdASjDHk5+cTHu7FE42VHj/1jJ1T9vJ7QPwgGHxLbacfnaR7+Uo1A78IgqSkJLKzszl8+LDdpXil8PBwkpKS7C7D2ss/lumyh+8czy9wObU2PNrq5Afd7Dxjpz900L18pTzJL4IgNDSU1NRUu8tQrqr38uufsVNxwnpegqy9/MQhMORntWfs6F6+Ui3OL4JANaOmng5Zs5e/pfbg7aEtDezlD4Aht9ZeiNWht+7lK+UlNAhUXaebprv0eN0Dt4e2NrKXf4G1l995gNXxt03UvXylvJgGgaqresqND26HlEtg11LoPBD+dQ8U7K9tFx5jdfRDbq0d1unYB0Ij7KpcKXWWNAjUqSJjrb37bYus5ZICSEyDC26vPWOnbYLu5SvlJzQIVK2qKvh6Dix7Aqoc1g1S9q6BCX/WK2WV8mMaBMpSkAWL7rZm0gwOg6mvQp9rTp1UTSnld4LsLkDZzBj4/j2YO9yaT7/vZLj5QysEoO403Uopv6TfCALZyaPwyUPWsYDki+HaF6w7aNWnk6gp5dc0CAJVxjJYdA+czIfLZsGIB/QG6UoFKA2CQFN+EpbNgm/nWRd13fy+NVOnUipgaRAEkpzvYMEMyN8Fw+6By34PoV48GZ1SqkVoEAQCRyWs/Sus/iO06QQ/+xd0G2N3VUopL6FB4O/yd1vfAnI2wICfwlWzISLG7qqUUl5Eg8BfGQMbX4Wlj0FwKNwwH/pfb3dVSikv5NHrCERkvIjsFJEMEXmkkTY/FZFtIrJVRN72ZD0Bo+gQvD0VPnkQugyFu7/SEFBKNcpj3whEJBiYA1wBZAPrRWSxMWabS5uewKPACGPMMRHp6Kl6Asb2T+Dj+6H8BFz5J7hwOgTpdYNKqcZ5cmhoKJBhjNkDICLvApOAbS5tpgNzjDHHAIwxeR6sx7+VFcFnj8DmN63TQa+dBx17212VUsoHeDIIEoEsl+Vs4KJ6bc4DEJEvgWDgCWPM5/V/kIjMAGYAJCcne6RYn7bvK1j4SyjMgkt+DaN/AyFhdlellPIRdh8sDgF6AmOAJGCNiAwwxhS4NjLGzAPmAaSlpZmWLtJrVZbDqv+17irWriv8/DNIHmZ3VUopH+PJIMgBurgsJznXucoGvjHGVACZIvIjVjCs92Bd/iFvOyyYbt0TeMjPYNz/Qqsou6tSSvkgTx5FXA/0FJFUEQkDpgGL67VZhPVtABGJwxoq2uPBmnxfVRV89U94cTQcPwDT3oGJ/9AQUEqdNY99IzDGVIrIvcBSrPH/+caYrSLyJLDBGLPY+dxPRGQb4ABmGmPyPVWTzyvMtu4ZkLkGzrvSCoA2HeyuSinl48QY3xpyT0tLMxs2bLC7jJb3wwfw6f+DqkoY/wdrOEhvFamUcpOIbDTGpDX0nN0Hi9WZnDwKS34NWz6CpKFw3YvQvpvdVSml/IgGgTfbvRIW/QpO5MHY38GIByFY/8mUUs1LexVvVFFi3UD+mxcgrhfc+A4kDLK7KqWUn9Ig8Da5m63ZQo/shIvugsufgNAIu6tSSvkxDQJv4aiEL/8Oq/4ArTvArQuh+1i7q1JKBQANAm9wdA8svAuyvoF+18GEv0Bke7urUkoFCA0COxkDm96Azx8FCYbrXoKBU+yuSikVYDQI7FJ82JoueucSSB0Fk+dCdJLdVSmlvNCiTTnMXrqT3IISEmIimDmuF5MHJzbbz9cgsMOOJbD4Pmvq6HF/sA4K6z0DlFINWLQph0cXpFNS4QAgp6CERxekAzRbGGjv05LKiq0AePdGaBsPv1wNF/9KQ0Ap1ajZS3fWhEC1kgoHs5fubLb30G8ELWX/N7BwBhzbByMfgjGP6T0DlFKNOlFWyYodeeQUlDT4fG4j68+GBoGnVZbD6j/C2r9axwB+vgS6Dre7KqWUFzpZbnX+n/5wgJU78yitqCJIoKqBKeESYprv+iINAk86vNO6Z8CB72HwLdbxgPC2dlellPIi1Z3/kvQDrNhhdf4doloxNa0LVw2IJ+dYCb9dtKXO8FBEaDAzx/Vqtho0CDyhqgq+nQfLZkFYa5j6JvS5xu6qlFJe4mR5JSt3HGZJ+gGW7zhEaUUVcW1a8VNn539hSnuCg2pnFw4KEj1ryKccz7UmituzEnqOs+4ZENXJ7qqUUjYrKXewcqc17LNiRx4lFQ7i2oQx5QKr8x+aWrfzdzV5cGKzdvz1aRA0py0fwScPg6Mcrv4bXPBzvWeAUgGspNzBqp15fJJ+gBXbazv/6y9IZMKAhNN2/i1Jg6A5lByDJTMh/QNITIPr5kFsd7urUkrZoLrz/9Q55n+y3EFs6zCuG5LIhIHxXJQa6xWdvysNgnO1Z7V1+8iig3Dpb2Hkw3rPAKUCTGlFded/kOXbD9V0/tcOTmSCc9gnJNh7rxfSHutsVZTC8ifh6zkQ2xPu/AISL7C7KqVUC7E6f+cB3+2HOFHuoH3rMCY7O/+LvLzzd6VBcDYO/GDdM+DwdrhwOlzxJIRF2l2VUsrDSiscrP7xMJ/+UNv5t4sMZeIgq/Mf1s13On9XGgRNUeWAdc/Biv+ByFi4+SPoebndVSmlPKi0wsGaHw/zafoBlm/Po7is0tn5JzBhQILPdv6uNAjcdWyvdc+A/V9B30lw9d/1ngFK+anqzn9J+gGWuXT+Vw+MZ8LAeIZ1iyXUxzt/VxoEZ2IMbH4LPvsNSBBc+yIMnKqnhSrlZ8oqHaz58QhL0g/wxbZDFJdVEuPs/K8aEM/F3f2r83elQXA6J47Axw/Ajk+g60i4di7EJNtdlVKqmZRVOviPS+dfVFZJdEQoEwbEc9XAeIb7cefvyqNBICLjgWeBYOAlY8wz9Z6/HZgN5DhXPW+MecmTNbntx6Xwr3uhtAB+8jQMu0eni1bKD5RVOli76wif/lC3879yQGcmDEwImM7flVtBICILgJeBz4wxVW6+JhiYA1wBZAPrRWSxMWZbvabvGWPubULNnlV+Av79OGyYD536w88WQad+dlellDoH5ZVVrM04zCfVnX+p1fmP79+ZCQPjGd49jrCQwOr8Xbn7jeCfwM+B50TkA+AVY8yZ7oowFMgwxuwBEJF3gUlA/SDwHtkbrNlCj2bC8Pth7OMQ0sruqpRSZ6G68//0h4P8e9tBikoraRsewvh+nblqYDwjArzzd+VWEBhjlgHLRCQauNH5OAv4P+BNY0xFAy9LBLJclrOBixpod72IjAJ+BB4yxmTVbyAiM4AZAMnJHhijd1TAmtmw5s/QNgFu/wRSRjb/+yilPKq8soovM47wafoB/r31IMdLK4kKD2Fcv85MGBDPiB7a+TfE7WMEIhIL3ALcCmwC3gJGArcBY87y/T8G3jHGlInIL4HXgLH1Gxlj5gHzANLS0hq4RcM5OLLL+haQuwnOvwmufAbCo5v1LZRSnlNeWcWXu4+w5IcDLHXp/H/StzMTBnZmZI8O2vmfgbvHCBYCvYA3gGuMMQecT70nIhsaeVkO0MVlOYnag8IAGGPyXRZfAv7kTj3NwhhY/xL8+3cQGgE/fd26PkAp5fUqHM49/x8O8O9thygsqSAqPIQr+nbi6oHWnn+rkGC7y/QZ7n4jeM4Ys7KhJ4wxaY28Zj3QU0RSsQJgGnCTawMRiXcJlYnAdjfrcd/av0PiEEgdVbtuy0JY8TQczYAel8OkORDVudnfWinVfCocVazbnc+nP+SydKuz829ldf4TBsYzsqd2/mfL3SDoKyKbjDEFACLSDrjRGPPPxl5gjKkUkXuBpVinj843xmwVkSeBDcaYxcD9IjIRqASOArefw+/SsMQh8MHtMOVVKwxW/sG6h3BQKEz4C6T9Qi8OU8pLVXf+S344wNJtByk4Wdv5XzUgnkvO086/OYgxZx5yF5HNxphB9dZtMsYM9lhljUhLSzMbNjQ2GtWIzDXw/m0QFQ95W63ZQm98B+J6eqZIpdRZq3BU8dXufJakH+DzrVbn38a18+8ZR3iodv5NJSIbGxvBcfcbQbCIiHGmhvMagbDmKtDjUkdBh17WPEHJw+G2xRAcandVSgWsRZty6tyD9/9d0ZMObcP51HnA99jJClqHBTuHfRK08/cwd4Pgc6wDwy86l3/pXOcbMtfA4Z0w+FbYucQKBNdjBkqpFrNoUw6PLkinpMIBQE5BCQ9/8AMArcOCubxvJyYMiGfUeR20828h7gbBb7A6/7udy19gneXj/TLXWMcIfvqa1flXL1cfM1BKtahnPttREwKu2rcOY90jY7Xzt4G7F5RVAXOdf3xLznd1O/3UUdZyzncaBEq1oC05hcxfm8nB46UNPn/sRLmGgE3cvY6gJ/AHoC8QXr3eGNPNQ3U1n5EPnroudZSGgFItwFFlWLb9EC+vzeTbzKO0DgumdatgTpSd+o0gISbChgoVuD809AowC/gbcCnWvEN6qZ5SqkHFZZW8vz6LV9ftZf/RkyTGRPD4hD789MIurNieV+cYAUBEaDAzx/WyseLA5m4QRBhjljvPHNoHPCEiG4Hfe7A2pZSPyTp6ktfW7eW99VkUlVWS1rUdj1zZm5/07VRzO8fJgxMB6pw1NHNcr5r1quW5GwRlIhIE7HJeJJYDtPFcWUopX2GMYeO+Y7y8NpOlWw8SJMJVA+K5Y2Qqg7rENPiayYMTteP3Iu4GwQNAJHA/8BTW8NBtnipKKeX9KhxVLEk/wPy1mXyfXUh0RCgzRnXntuFdiY/W8X5fcsYgcF48NtUY82ugGOv4gFIqQBWcLOftb/fz+rp9HDxeSre41jw1uT/XD0kkMkzvfuuLzvivZoxxiIhOzq9UgMvIK+aVLzP56LtsSiuqGNkjjj9cN4DR53UgKEjn6/Jl7sb3JhFZDHwAnKheaYxZ4JGqlFJewRjD2owjvLw2k1U7DxMWEsTkQQncMTKV3p3b2l2eaibuBkE4kE/dm8YYQINAKT9UWuHgX5tzmL92LzsPFRHXphUPXX4eNw9LJq6N3r7V37h7ZbEeF1AqAOQVlfLmV/t465v95J8op3fnKGbfMJCJgxJ0umc/5u6Vxa9gfQOowxhzR7NXpJRqcVtzC5m/di8ff59LRVUVl/XuyB0jU7m4Wyyi9+vwe+4ODX3i8jgcuBbIbf5ylFItxVFlWLEjj5fX7uHrPUeJDAvmxqFduH1EKqlxre0uT7Ugd4eGPnJdFpF3gLUeqUgp5VEnyir5YEMWr6zby778kyREh/Polb2ZdmEy0ZF6n45AdLYn/fYEOjZnIUopz8opKOG1dXt559v9FJVWMjg5hpnjejG+X+ea6R9UYHL3GEERdY8RHMS6R4FSystt3HeM+Wsz+XzrQQCu7N+ZO0amMiS5nc2VKW/h7tBQlKcLUUo1nwpHFZ9tOcj8tZlsziogKjyEO0em8rPhKSTqdM+qHne/EVwLrDDGFDqXY4AxxphFnixOKdU0hScreGf9fl5bt5cDhaWkxrXmyUn9uH5IEq1b6fQPqmHu/s+YZYxZWL1gjCkQkVmABoFSXmDP4WJe+XIvH27MpqTCwfDusTw1qT9je3fU6R/UGbkbBA0dSdLdC6VsZIxh3e585q/NZPmOPMKCg5g4KIE7RqTSN0Gnf1Duc7cz3yAifwXmOJfvATZ6piSl1OmUVjhY/H0u89dmsuNgEbGtw3jgsp7cMqwrHaJ0+gfVdO4GwX3A74D3sM4e+gIrDE5LRMYDzwLBwEvGmGcaaXc98CFwoTFmg5s1KRVQDheV8ebX+3jrm30cKbamf/jT9db0D3rTd3Uu3D1r6ATwSFN+sPM+BnOAK4BsYL2ILDbGbKvXLgrrxjffNOXnKxUoth84zvy1mfxrcy7ljirG9u7IL0amMry7Tv+gmoe7Zw19AUwxxhQ4l9sB7xpjxp3mZUOBDGPMHudr3gUmAdvqtXsK+CMws4m1K+W3qqoMK3fm8fLaTNbtziciNJipF3bh5yNS6NZB7xKrmpe7Q0Nx1SEAYIw5JiJnurI4EchyWc4GLnJtICJDgC7GmE9FpNEgEJEZwAyA5ORkN0tWyvecKKvko++yeeXLvWQeOUHntuH8ZnxvbhzahZjIMLvLU37K3SCoEpFkY8x+ABFJoYHZSJtCRIKAvwK3n6mtMWYeMA8gLS3tnN5XKW+UW1DCa1/t5Z1v9nO8tJLzu8Tw3I2DubJ/Z0J1+gflYe4GwW+BtSKyGhDgEpx76KeRA3RxWU5yrqsWBfQHVjnHOTsDi0Vkoh4wVoFi0/5jvLw2k8+2HMQYw5X947ljZApDktvp+L9qMe4eLP5cRNKwOv9NWBeSlZzhZeuBniKSihUA04CbXH5mIRBXvSwiq4Bfawgof1fpqOLzrdb0D9/tLyCqVQh3jEjhtuEpJLWLtLs8FYDcPVh8J9aZPUnAZmAY8BV1b11ZhzGmUkTuBZZinT463xizVUSeBDYYYxafa/FK+ZLCkgreW7+f19btI6eghK6xkTxxTV9uSOtCG53+QdnI3f99DwAXAl8bYy4Vkd7A/57pRcaYJcCSeut+30jbMW7WopRP2XvkBK98mckHG7M5We7gotT2zLqmL5f16USwTv+gvIC7QVBqjCkVEUSklTFmh4j08mhlSvmIRZtymL10J7kFJSTERDBzXC8mDUrgqz210z+EBAnXnG9N/9A/MdrukpWqw90gyHbOOLoI+EJEjgH7PFeWUr5h0aYcHl2QTkmFA7Bu/jLzw+/50+c7yC0spX3rMO67tAe3DOtKx7bhNlerVMPcPVh8rfPhEyKyEogGPvdYVUr5iNlLd9aEQLUKhyGvqIxnrhvA5MGJOv2D8npNPkJljFntiUKU8kW5BQ2fPOeoMkwbqhc/Kt+gpyoodRaOnijnpf/safT5BL0LmPIhGgRKNcHRE+X833/28Pq6vZyscHB+l2i2HyiirLKqpk1EaDAzx+m5FMp3aBAo5Yb84jLm/WcPb3y1j5IKB2ssjAAAABCsSURBVFcPTOC+sT04r1NUg2cNTR6caHfJSrlNg0Cp0zhSXMb/rdnD61/to7TSwTXOAOjZKaqmzeTBidrxK5+mQaBUAw4XlTFvzW7e/Ho/ZZUOJp6fwL1je9Kjo04BrfyPBoFSLvKKSpm3eg9vfrOP8soqJg1K5N6xPeiu9wBQfkyDQCmsAHhx9R7ecgbAZGcA6E1gVCDQIFABLe94KXNX7+btb/ZTWWVqAiA1rrXdpSnVYjQIVEA6dLyUuat28863VgBcOziRey/tQYoGgApAGgQqoBwsLGXuqgzeWZ+Fo8pw/ZBE7rm0B11jNQBU4NIgUAHhQGEJc1ft5t1vs6gyhuuHJHHPpT1IjtUbwSilQaD8Wm5BCf9clcH767OpMoYpaUn8akwPurTXAFCqmgaB8ks5BSX8c2UG72/IAuCGC7rwqzHdNQCUaoAGgfIr2cdO8s9Vu/nAGQBT0qwA0HsBK9U4DQLlF7KOWgHw4UYrAKZe2IW7x/QgUWcBVeqMNAiUT8s6epI5KzP4cGM2QSJMuzCZu8d012mglWoCDQLlk/bnWwHw0XdWANx0kRUA8dEaAEo1lQaB8in78k/w/IoMFmzKIThIuGVYV+4a3Z3O0Xo/YKXOlgaB8gl7j5zg+ZUZLNyUQ0iQcOuwrtw9pjud9IbwSp0zjwaBiIwHngWCgZeMMc/Ue/4u4B7AARQDM4wx2zxZk/ItmUdO8I8Vu/jX5lxCgoTbLk7hrtHd6KgBoFSz8VgQiEgwMAe4AsgG1ovI4nod/dvGmBec7ScCfwXGe6om5Tv2HC7m+RUZLNqcQ1hIELcPT+GXo7vRMUoDQKnm5slvBEOBDGPMHgAReReYBNQEgTHmuEv71oDxYD3KB+x2BsC/nAFwx4hUZmgAKOVRngyCRCDLZTkbuKh+IxG5B3gYCAPGerAe5cUy8or5x4pdfPx9Lq1Cgrnzkm5Mv6QbHaJa2V2aUn7P9oPFxpg5wBwRuQl4HLitfhsRmQHMAEhOTm7ZApVHZeQV8dzyDD7+IZfwkGCmX9KN6aO6EddGA0CpluLJIMgBurgsJznXNeZdYG5DTxhj5gHzANLS0nT4yA/8eKiI55bv4tP0A0SEBvPLUd2ZfkkqsRoASrU4TwbBeqCniKRiBcA04CbXBiLS0xizy7k4AdiF8ms7Dxbx3IpdLEk/QGRoMHeN7s70S7rRvnWY3aUpFbA8FgTGmEoRuRdYinX66HxjzFYReRLYYIxZDNwrIpcDFcAxGhgWUv5hx8HjPLd8F0vSD9I6LJhfjenOnSO70U4DQCnbefQYgTFmCbCk3rrfuzx+wJPvr+y3/YAVAJ9tOUibViHce2kPfjEyVQNAKS9i+8Fi5Z+25VoB8PnWg0S1CuG+sVYAxERqACjlbTQIVLPaklPIc8t38e9th4hqFcL9l/XkFyNSiY4Mtbs0pVQjNAhUs9iSU8izy3fxxbZDRIWH8MBlPblDA0Apn6BBoM5JenYhzy7/kWXb82gbHsJDl5/H7SNSiI7QAFDKV2gQqLPyQ3YBzy7bxfIdeURHhPLwFVYAtA3XAFDK12gQqCb5PquAZ5fvYsWOPGIiQ/n1T87jtuEpRGkAKOWzNAjUKRZtymH20p3kFpSQEBPBzHG96BobybPLd7Fq52FiIkOZOa4XP7u4qwaAUn5Ag0DVsWhTDo8uSKekwgFATkEJD7+/mSoD7ZwBcNvwFNq00v86SvkL/TSrOmYv3VkTAtWqDLQND+E/vxmrAaCUHwqyuwDlPYwx5BSUNPhcUWmlhoBSfko/2QpjDMu35/GPlRmNtkmIiWjBipRSLUmDIIA5qgyfbTnAnJW72X7gOEntIpiSlsTH3+dSWlFV0y4iNJiZ43rZWKlSypM0CAJQhaOKxZtzmbMqgz2HT9CtQ2v+MuV8Jg5KIDQ4iBHd4045a2jy4ES7y1ZKeYgGQQApq3Tw4cZs5q7aTfaxEnp3jmLOTUMY378zwUFS027y4ETt+JUKIBoEAeBkeSXvfJvFvDW7OXS8jEFdYvjvif0Y27sjInLmH6CU8msaBH6sqLSC17/ax8trMzl6opxh3drzlymDGNEjVgNAKVVDg8APHTtRzitfZvLqur0cL61k9HkduHdsDy5MaW93aUopL6RB4Efyikp5+T+ZvPH1Pk6WOxjXrxP3XtqTAUnRdpemlPJiGgR+IKeghHmrd/Pu+iwqHFVcc34CvxrTg16do+wuTSnlAzQIfNjeIyeYu2o3H32XDcD1Q5K4e0x3UuJa21yZUsqXaBD4oB8PFTFnZQYff59LSHAQN1+UzIzR3UnUq3+VUmdBg8CHpGcX8vzKXSzdeojIsGCmX9KNX1ySSseocLtLU0r5MA0CH7Bh71H+sSKD1T8eJio8hPvH9uDnI1Jp1zrM7tKUUn5Ag8BLGWP4MiOf51fu4us9R2nfOoyZ43px68Vd9XaQSqlm5dEgEJHxwLNAMPCSMeaZes8/DNwJVAKHgTuMMfs8WZO3q54J9PmVGWzOKqBT21b87uq+3Di0C5FhmttKqebnsZ5FRIKBOcAVQDawXkQWG2O2uTTbBKQZY06KyN3An4CpnqrJmzmqDJ9vOcjzKzNqZgL9n2v7c8MFSbQKCba7PKWUH/PkLuZQIMMYswdARN4FJgE1QWCMWenS/mvgFg/W45XONBOoUkp5mieDIBHIclnOBi46TftfAJ95sB6vUj0T6Aurd5N11JoJ9PmbBnNl//g6M4EqpZSnecWgs4jcAqQBoxt5fgYwAyA5ObkFK2t+JeUO3v52f81MoOd3iWHW1f24rI/OBKqUsocngyAH6OKynORcV4eIXA78FhhtjClr6AcZY+YB8wDS0tJM85fqeUWlFbzx9T5e/k8m+SfKuShVZwJVSnkHTwbBeqCniKRiBcA04CbXBiIyGHgRGG+MyfNgLbY5dqKcV9bt5dUvM3UmUKWUV/JYEBhjKkXkXmAp1umj840xW0XkSWCDMWYxMBtoA3zg3Cveb4yZ6KmaWpLOBKqU8hUePUZgjFkCLKm37vcujy/35PvbQWcCVUr5Gq84WOwPqmcCXbApG2PguiGJ3D2mB6k6E6hSystpEJyjHw8V8c+VGSx2zgR649BkZozqRlK7SLtLU0opt2gQnKUtOYU8vyKDz7ceJDIsmDsv6cadI1Pp2FZnAlVK+RYNgibauM+aCXTVTp0JVCnlHzQI3GCMYd3ufP6xQmcCVUr5Hw2C0zDGsGJHHv9YYc0E2jGqFY9P6MNNFyXrTKBKKb+hvVkDGpoJ9OnJ1kyg4aE6E6hSyr9oELiodFSx+Ptc5qzMYLdzJtA/TzmfSToTqFLKj2kQoDOBKqUCW0AHQUm5g3e+3c+8NXs4eLxUZwJVSgWkgAiCRZtymL10J7kFJSTERHDf2O4cPVlRZybQ2VMGMrJHnAaAUirg+H0QLNqUw6ML0impcADWXECPLNgCoDOBKqUUARAEs5furAkBVx2iWvHaHUNtqEgppbyL358Kk1tQ0uD6I0UN3gNHKaUCjt8HQUJMRJPWK6VUoPH7IJg5rhcR9S4CiwgNZua4XjZVpJRS3sXvjxFMHpwIUOesoZnjetWsV0qpQOf3QQBWGGjHr5RSDfP7oSGllFKnp0GglFIBToNAKaUCnAaBUkoFOA0CpZQKcGKMsbuGJhGRw8C+s3x5HHCkGctpLlpX02hdTeettWldTXMudXU1xnRo6AmfC4JzISIbjDFpdtdRn9bVNFpX03lrbVpX03iqLh0aUkqpAKdBoJRSAS7QgmCe3QU0QutqGq2r6by1Nq2raTxSV0AdI1BKKXWqQPtGoJRSqh4NAqWUCnB+GQQiMl5EdopIhog80sDzrUTkPefz34hIipfUdbuIHBaRzc4/d7ZQXfNFJE9EtjTyvIjIc866fxCRIV5S1xgRKXTZXr9vgZq6iMhKEdkmIltF5IEG2rT49nKzLju2V7iIfCsi3zvr+u8G2rT459HNumz5PDrfO1hENonIJw081/zbyxjjV3+AYGA30A0IA74H+tZr8yvgBefjacB7XlLX7cDzNmyzUcAQYEsjz18FfAYIMAz4xkvqGgN80sLbKh4Y4nwcBfzYwL9ji28vN+uyY3sJ0Mb5OBT4BhhWr40dn0d36rLl8+h874eBtxv69/LE9vLHbwRDgQxjzB5jTDnwLjCpXptJwGvOxx8Cl4mIeEFdtjDGrAGOnqbJJOB1Y/kaiBGReC+oq8UZYw4YY75zPi4CtgP1b3bR4tvLzbpanHMbFDsXQ51/6p+h0uKfRzfrsoWIJAETgJcaadLs28sfgyARyHJZzubUD0RNG2NMJVAIxHpBXQDXO4cTPhSRLh6uyV3u1m6Hi51f7z8TkX4t+cbOr+SDsfYmXdm6vU5TF9iwvZzDHJuBPOALY0yj26sFP4/u1AX2fB7/DvwXUNXI882+vfwxCHzZx0CKMWYg8AW1qa8a9h3W/CnnA/8AFrXUG4tIG+Aj4EFjzPGWet8zOUNdtmwvY4zDGDMISAKGikj/lnjfM3Gjrhb/PIrI1UCeMWajp9/LlT8GQQ7gmtxJznUNthGRECAayLe7LmNMvjGmzLn4EnCBh2tylzvbtMUZY45Xf703xiwBQkUkztPvKyKhWJ3tW8aYBQ00sWV7nakuu7aXy/sXACuB8fWesuPzeMa6bPo8jgAmisherOHjsSLyZr02zb69/DEI1gM9RSRVRMKwDqYsrtdmMXCb8/ENwArjPPJiZ131xpEnYo3zeoPFwM+cZ8MMAwqNMQfsLkpEOlePjYrIUKz/zx7tQJzv9zKw3Rjz10aatfj2cqcum7ZXBxGJcT6OAK4AdtRr1uKfR3fqsuPzaIx51BiTZIxJweojVhhjbqnXrNm3l9/dvN4YUyki9wJLsc7UmW+M2SoiTwIbjDGLsT4wb4hIBtbByGleUtf9IjIRqHTWdbun6wIQkXewziiJE5FsYBbWwTOMMS8AS7DOhMkATgI/95K6bgDuFpFKoASY1gKBPgK4FUh3ji8DPAYku9Rlx/Zypy47tlc88JqIBGMFz/vGmE/s/jy6WZctn8eGeHp76RQTSikV4PxxaEgppVQTaBAopVSA0yBQSqkAp0GglFIBToNAKaUCnAaBUi1IrBlAT5lRUik7aRAopVSA0yBQqgEicotzvvrNIvKic4KyYhH5m3P++uUi0sHZdpCIfO2cnGyhiLRzru8hIsuck7x9JyLdnT++jXMSsx0i8lYLzHyr1GlpEChVj4j0AaYCI5yTkjmAm4HWWFd39gNWY13pDPA68Bvn5GTpLuvfAuY4J3kbDlRPMzEYeBDoi3V/ihEe/6WUOg2/m2JCqWZwGdYEY+udO+sRWFMVVwHvOdu8CSwQkWggxhiz2rn+NeADEYkCEo0xCwGMMaUAzp/3rTEm27m8GUgB1nr+11KqYRoESp1KgNeMMY/WWSnyu3rtznZ+ljKXxw70c6hspkNDSp1qOXCDiHQEEJH2ItIV6/Nyg7PNTcBaY0whcExELnGuvxVY7bxLWLaITHb+jFYiEtmiv4VSbtI9EaXqMcZsE5HHgX+LSBBQAdwDnMC6gcnjWENFU50vuQ14wdnR76F2ttFbgRedM0dWAFNa8NdQym06+6hSbhKRYmNMG7vrUKq56dCQUkoFOP1GoJRSAU6/ESilVIDTIFBKqQCnQaCUUgFOg0AppQKcBoFSSgW4/w+uElL4O6PKLQAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["## 20.4 활성화 함수\n","\n","- 층 뒤에 적용하는 함수로, 뉴런에 발화에 해당한다\n","- 완전연결층에서는 입력을 선형 변환된 것을 출력하지만 활성화 함수를 이용해서 비선형성을 갖게 한다"],"metadata":{"id":"t0WcyDutVGC9"}},{"cell_type":"markdown","source":["### 20.4.1 시그모이드 함수\n","\n","- 1 / (1 + np.exp(-x))"],"metadata":{"id":"4YU13BxaVVzd"}},{"cell_type":"markdown","source":["### 20.4.2 ReLU 함수\n","\n","- 0 (x<0)\n","- x (x>0)\n","- 출력이 어떤 구간에도 수렴되지 않고 극단적인 출력값이 생성될 가능성이 있다"],"metadata":{"id":"8x5yRAVgVgLU"}},{"cell_type":"markdown","source":["## 20.5 손실 함수\n","\n","- 학습시 모델의 출력과 데이터의 차이를 평가하는 함수\n","- 이 손실 함수를 최소화하기 위해 오차역전파로 각 층의 가중치를 갱신한다"],"metadata":{"id":"Oh8HIKfFVu-2"}},{"cell_type":"markdown","source":["### 20.5.1 제곱 오차\n","\n","- 정답값과 예측값의 오차에 제곱을 한 값. 회귀에 적합하며 최소치 부근에서 천천히 갱신되므로 학습이 수렴하기 쉽다"],"metadata":{"id":"4Y2qV5O_V9tT"}},{"cell_type":"markdown","source":["### 20.5.2 교차 엔트로피 오차\n","\n","- 이항 분류 평가에 특화되있으며 주로 분류 모델의 오차 함수로 사용된다\n","- 정답 라벨과 예측 라벨의 값이 가까울수록 작은 값이 된다"],"metadata":{"id":"jnAuuYddWM1r"}},{"cell_type":"markdown","source":["## 20.6 최적화 함수\n","\n","- 가중치 갱신은 오차 함수를 각 가중치로 미분한 값을 바탕으로 갱신해야 할 방향과 어느 정도 갱신할지를 결정한다\n","- 손실 함수, epoch 수 등 여러 정보를 바탕으로 가중치를 갱신한다\n","- 최적화 함수는 하이퍼파라미터이며, 맞지 않는 함수 사용시 학습에 많은 시간이 걸릴 수도 있다"],"metadata":{"id":"SfIM_KWCWbsC"}},{"cell_type":"markdown","source":["## 20.7 학습률\n","\n","- 각 층의 가중치를 한번에 얼마나 갱신할지 결정하는 하이퍼파라미터\n","- 너무 크면 발산하거나 너무 작으면 수렴하는데 오랜 시간이 걸리므로 적절한 학습률을 지정하는 것이 중요하다"],"metadata":{"id":"tGYNek7HWuDE"}},{"cell_type":"code","source":["(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","X_train = X_train.reshape(X_train.shape[0], 784)[:6000]\n","X_test = X_test.reshape(X_test.shape[0], 784)[:1000]\n","y_train = to_categorical(y_train)[:6000]\n","y_test = to_categorical(y_test)[:1000]\n","\n","model = Sequential()\n","model.add(layers.Dense(256, input_dim=784))\n","model.add(layers.Activation('sigmoid'))\n","\n","def funcA():\n","    global lr\n","    lr = 0.01\n","\n","def funcB():\n","    global lr\n","    lr = 0.1\n","\n","def funcC():\n","    global lr\n","    lr = 1.0\n","\n","# funcA()\n","funcB()\n","# funcC()\n","\n","model.add(Dense(10, activation='softmax'))\n","\n","sgd = keras.optimizers.SGD(learning_rate=lr) \n","model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy']) \n","\n","history = model.fit(X_train, y_train, batch_size=32, epochs=5, verbose=1) \n","\n","loss, acc = model.evaluate(X_test, y_test)\n","print(f'loss : {loss} \\nacc : {acc}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bfpn_EmRU-ni","executionInfo":{"status":"ok","timestamp":1669188152728,"user_tz":-540,"elapsed":5882,"user":{"displayName":"두루미","userId":"06775262425078058900"}},"outputId":"bed1f96d-098e-44cf-a9ce-27ebf16e1c4e"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","188/188 [==============================] - 1s 4ms/step - loss: 1.2457 - accuracy: 0.6082\n","Epoch 2/5\n","188/188 [==============================] - 1s 4ms/step - loss: 0.7939 - accuracy: 0.7620\n","Epoch 3/5\n","188/188 [==============================] - 1s 6ms/step - loss: 0.6907 - accuracy: 0.7975\n","Epoch 4/5\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6748 - accuracy: 0.8067\n","Epoch 5/5\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6768 - accuracy: 0.7945\n","32/32 [==============================] - 0s 3ms/step - loss: 0.7503 - accuracy: 0.7420\n","loss : 0.7502784132957458 \n","acc : 0.7419999837875366\n"]}]},{"cell_type":"markdown","source":["## 20.8 미니배치 학습\n","\n","- 한번에 전달하는 데이터 수를 배치 사이즈라 한다\n","- 복수의 데이터를 이용해 가중치를 갱신하면 극단적으로 바뀐 데이터의 영향을 덜받고 병렬 계산이 가능하여 계산시간이 단축된다\n","- 배치크기가 1인 학습은 온라인 학습(확률적 경사하강법)\n","- 배치 크기를 전체 데이터수로 지정하는 방식은 배치 학습(경사하강법)\n","- 이 둘의 중간을 미니배치 학습이라 한다"],"metadata":{"id":"ofnB8vHMhfYX"}},{"cell_type":"code","source":["(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","X_train = X_train.reshape(X_train.shape[0], 784)[:6000]\n","X_test = X_test.reshape(X_test.shape[0], 784)[:1000]\n","y_train = to_categorical(y_train)[:6000]\n","y_test = to_categorical(y_test)[:1000]\n","\n","model = Sequential()\n","model.add(layers.Dense(256, input_dim=784))\n","model.add(layers.Activation('sigmoid'))\n","\n","def funcA():\n","    global batch_size\n","    batch_size = 16\n","\n","def funcB():\n","    global batch_size\n","    batch_size = 32\n","\n","def funcC():\n","    global batch_size\n","    batch_size = 64\n","\n","# funcA()\n","# funcB()\n","funcC()\n","\n","model.add(Dense(10, activation='softmax'))\n","\n","sgd = keras.optimizers.SGD(learning_rate=lr) \n","model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy']) \n","\n","history = model.fit(X_train, y_train, batch_size=batch_size, epochs=5, verbose=1) \n","\n","loss, acc = model.evaluate(X_test, y_test)\n","print(f'loss : {loss} \\nacc : {acc}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h98AwJk8U-lB","executionInfo":{"status":"ok","timestamp":1669191014446,"user_tz":-540,"elapsed":3638,"user":{"displayName":"두루미","userId":"06775262425078058900"}},"outputId":"612f92e9-4347-41bd-b0f2-d2e3de9e84d1"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","94/94 [==============================] - 1s 5ms/step - loss: 1.1188 - accuracy: 0.6877\n","Epoch 2/5\n","94/94 [==============================] - 0s 5ms/step - loss: 0.5994 - accuracy: 0.8483\n","Epoch 3/5\n","94/94 [==============================] - 0s 5ms/step - loss: 0.5264 - accuracy: 0.8643\n","Epoch 4/5\n","94/94 [==============================] - 0s 5ms/step - loss: 0.4741 - accuracy: 0.8785\n","Epoch 5/5\n","94/94 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.8882\n","32/32 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.8560\n","loss : 0.5224056243896484 \n","acc : 0.8560000061988831\n"]}]},{"cell_type":"markdown","source":["## 20.9 반복 학습\n","\n","- 모델의 정확도를 높이기 위해 동일한 훈련 데이터로 여러번 학습시킨다\n","- epoch수가 높다고 모델의 정확도가 계속 오르진 않는다. 과하면 과적합이 발생하기에 적절한 수를 정해줘야한다"],"metadata":{"id":"tlLaSG0kiafb"}},{"cell_type":"code","source":["(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","X_train = X_train.reshape(X_train.shape[0], 784)[:6000]\n","X_test = X_test.reshape(X_test.shape[0], 784)[:1000]\n","y_train = to_categorical(y_train)[:6000]\n","y_test = to_categorical(y_test)[:1000]\n","\n","model = Sequential()\n","model.add(layers.Dense(256, input_dim=784))\n","model.add(layers.Activation('sigmoid'))\n","\n","def funcA():\n","    global epoch\n","    epoch = 5\n","\n","def funcB():\n","    global epoch\n","    epoch = 10\n","\n","def funcC():\n","    global epoch\n","    epoch = 60\n","\n","# funcA()\n","# funcB()\n","funcC()\n","\n","model.add(Dense(10, activation='softmax'))\n","\n","sgd = keras.optimizers.SGD(learning_rate=lr) \n","model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy']) \n","\n","history = model.fit(X_train, y_train, batch_size=32, epochs=epoch, verbose=1) \n","\n","loss, acc = model.evaluate(X_test, y_test)\n","print(f'loss : {loss} \\nacc : {acc}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WZ2lUnJQiYhi","executionInfo":{"status":"ok","timestamp":1669191201220,"user_tz":-540,"elapsed":83109,"user":{"displayName":"두루미","userId":"06775262425078058900"}},"outputId":"a8410c28-2770-4288-b538-819fba99d164"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/60\n","188/188 [==============================] - 1s 4ms/step - loss: 1.2713 - accuracy: 0.5990\n","Epoch 2/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.7784 - accuracy: 0.7700\n","Epoch 3/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6826 - accuracy: 0.8043\n","Epoch 4/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6735 - accuracy: 0.7955\n","Epoch 5/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6283 - accuracy: 0.8105\n","Epoch 6/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6136 - accuracy: 0.8085\n","Epoch 7/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6275 - accuracy: 0.8073\n","Epoch 8/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6076 - accuracy: 0.8167\n","Epoch 9/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5872 - accuracy: 0.8203\n","Epoch 10/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6227 - accuracy: 0.8112\n","Epoch 11/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5947 - accuracy: 0.8180\n","Epoch 12/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6378 - accuracy: 0.8102\n","Epoch 13/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6095 - accuracy: 0.8150\n","Epoch 14/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6131 - accuracy: 0.8070\n","Epoch 15/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5811 - accuracy: 0.8172\n","Epoch 16/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5827 - accuracy: 0.8113\n","Epoch 17/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5723 - accuracy: 0.8165\n","Epoch 18/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5362 - accuracy: 0.8320\n","Epoch 19/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5164 - accuracy: 0.8428\n","Epoch 20/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5494 - accuracy: 0.8290\n","Epoch 21/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6126 - accuracy: 0.8065\n","Epoch 22/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5695 - accuracy: 0.8178\n","Epoch 23/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5734 - accuracy: 0.8255\n","Epoch 24/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5546 - accuracy: 0.8262\n","Epoch 25/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5817 - accuracy: 0.8150\n","Epoch 26/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6241 - accuracy: 0.8010\n","Epoch 27/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.5668 - accuracy: 0.8220\n","Epoch 28/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6263 - accuracy: 0.7963\n","Epoch 29/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6552 - accuracy: 0.7837\n","Epoch 30/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6860 - accuracy: 0.7758\n","Epoch 31/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6833 - accuracy: 0.7770\n","Epoch 32/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6591 - accuracy: 0.7933\n","Epoch 33/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6446 - accuracy: 0.7975\n","Epoch 34/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6789 - accuracy: 0.7877\n","Epoch 35/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.7745 - accuracy: 0.7528\n","Epoch 36/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.7279 - accuracy: 0.7637\n","Epoch 37/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.7074 - accuracy: 0.7735\n","Epoch 38/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6326 - accuracy: 0.7988\n","Epoch 39/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6149 - accuracy: 0.8013\n","Epoch 40/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6611 - accuracy: 0.7905\n","Epoch 41/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6106 - accuracy: 0.8082\n","Epoch 42/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6300 - accuracy: 0.8027\n","Epoch 43/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6683 - accuracy: 0.7837\n","Epoch 44/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6092 - accuracy: 0.8008\n","Epoch 45/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6296 - accuracy: 0.7990\n","Epoch 46/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6528 - accuracy: 0.7858\n","Epoch 47/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.7272 - accuracy: 0.7557\n","Epoch 48/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.7149 - accuracy: 0.7642\n","Epoch 49/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6580 - accuracy: 0.7802\n","Epoch 50/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6394 - accuracy: 0.8023\n","Epoch 51/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6824 - accuracy: 0.7828\n","Epoch 52/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6901 - accuracy: 0.7685\n","Epoch 53/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6543 - accuracy: 0.7868\n","Epoch 54/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.7163 - accuracy: 0.7745\n","Epoch 55/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.7313 - accuracy: 0.7438\n","Epoch 56/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.7321 - accuracy: 0.7482\n","Epoch 57/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6894 - accuracy: 0.7668\n","Epoch 58/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6886 - accuracy: 0.7635\n","Epoch 59/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.6625 - accuracy: 0.7707\n","Epoch 60/60\n","188/188 [==============================] - 1s 4ms/step - loss: 0.7004 - accuracy: 0.7622\n","32/32 [==============================] - 0s 3ms/step - loss: 0.7592 - accuracy: 0.7350\n","loss : 0.7591526508331299 \n","acc : 0.7350000143051147\n"]}]},{"cell_type":"markdown","source":["## 연습 문제\n","\n","- 하이퍼파라미터는 활성화 함수, 드롭아웃 비율, 학습률, 최적화 함수, 오차 함수, 배치 사이즈, epoch수 등"],"metadata":{"id":"npfdljgBmJGw"}},{"cell_type":"code","source":["# 여기서 파이퍼파라미터 하나만 변경해서 0.85를 달성하라\n","# epoch=5 고정, 데이터 고정\n","\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","X_train = X_train.reshape(X_train.shape[0], 784)[:6000]\n","X_test = X_test.reshape(X_test.shape[0], 784)[:1000]\n","y_train = to_categorical(y_train)[:6000]\n","y_test = to_categorical(y_test)[:1000]\n","\n","# 변경 전 0.63\n","#---------------------------\n","model = Sequential()\n","model.add(Dense(256, input_dim=784))\n","model.add(Activation(\"sigmoid\"))\n","model.add(Dense(128))\n","model.add(Activation(\"sigmoid\"))\n","model.add(Dropout(rate=0.5))\n","model.add(Dense(10))\n","model.add(Activation(\"softmax\"))\n","\n","sgd = optimizers.SGD(lr=0.1)\n","model.compile(optimizer=sgd, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","model.fit(X_train, y_train, batch_size=10, epochs=5, verbose=1)\n","score = model.evaluate(X_test, y_test, verbose=0)\n","print(\"evaluate loss: {0[0]}\\nevaluate acc: {0[1]}\".format(score))\n","\n","#----------------------------"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fkyac1bdiytg","executionInfo":{"status":"ok","timestamp":1669191402097,"user_tz":-540,"elapsed":12064,"user":{"displayName":"두루미","userId":"06775262425078058900"}},"outputId":"ecef21fd-dddb-495a-8ba9-0d336581d342"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(SGD, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["600/600 [==============================] - 2s 3ms/step - loss: 1.7827 - accuracy: 0.3722\n","Epoch 2/5\n","600/600 [==============================] - 2s 3ms/step - loss: 1.3954 - accuracy: 0.4897\n","Epoch 3/5\n","600/600 [==============================] - 2s 4ms/step - loss: 1.2641 - accuracy: 0.5373\n","Epoch 4/5\n","600/600 [==============================] - 2s 4ms/step - loss: 1.3297 - accuracy: 0.5102\n","Epoch 5/5\n","600/600 [==============================] - 2s 3ms/step - loss: 1.1961 - accuracy: 0.5625\n","evaluate loss: 1.0303350687026978\n","evaluate acc: 0.6349999904632568\n"]}]},{"cell_type":"code","source":["# 여기서 파이퍼파라미터 하나만 변경해서 0.85를 달성하라\n","# epoch=5 고정, 데이터 고정\n","\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","X_train = X_train.reshape(X_train.shape[0], 784)[:6000]\n","X_test = X_test.reshape(X_test.shape[0], 784)[:1000]\n","y_train = to_categorical(y_train)[:6000]\n","y_test = to_categorical(y_test)[:1000]\n","\n","# 학습률 0.1 -> 0.01 변경\n","# 0.63 -> 0.83\n","#---------------------------\n","model = Sequential()\n","model.add(Dense(256, input_dim=784))\n","model.add(Activation(\"sigmoid\"))\n","model.add(Dense(128))\n","model.add(Activation(\"sigmoid\"))\n","model.add(Dropout(rate=0.5))\n","model.add(Dense(10))\n","model.add(Activation(\"softmax\"))\n","\n","sgd = optimizers.SGD(lr=0.01) # 0.1 -> 0.01 \n","model.compile(optimizer=sgd, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","model.fit(X_train, y_train, batch_size=10, epochs=5, verbose=1)\n","score = model.evaluate(X_test, y_test, verbose=0)\n","print(\"evaluate loss: {0[0]}\\nevaluate acc: {0[1]}\".format(score))\n","\n","#----------------------------"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dQ8qpw9qj1Gv","executionInfo":{"status":"ok","timestamp":1669191470516,"user_tz":-540,"elapsed":11891,"user":{"displayName":"두루미","userId":"06775262425078058900"}},"outputId":"b3826b4a-1be3-46ca-e9c4-8a4b2f45d2e2"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","600/600 [==============================] - 2s 3ms/step - loss: 2.0054 - accuracy: 0.3158\n","Epoch 2/5\n","600/600 [==============================] - 2s 4ms/step - loss: 1.3159 - accuracy: 0.5997\n","Epoch 3/5\n","600/600 [==============================] - 2s 4ms/step - loss: 0.9853 - accuracy: 0.7132\n","Epoch 4/5\n","600/600 [==============================] - 2s 3ms/step - loss: 0.8032 - accuracy: 0.7753\n","Epoch 5/5\n","600/600 [==============================] - 2s 4ms/step - loss: 0.6941 - accuracy: 0.8088\n","evaluate loss: 0.6043983697891235\n","evaluate acc: 0.8399999737739563\n"]}]},{"cell_type":"code","source":["# 여기서 파이퍼파라미터 하나만 변경해서 0.85를 달성하라\n","# epoch=5 고정, 데이터 고정\n","\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","X_train = X_train.reshape(X_train.shape[0], 784)[:6000]\n","X_test = X_test.reshape(X_test.shape[0], 784)[:1000]\n","y_train = to_categorical(y_train)[:6000]\n","y_test = to_categorical(y_test)[:1000]\n","\n","# batch_size 10 -> 32\n","# 0.63 -> 0.82\n","#---------------------------\n","model = Sequential()\n","model.add(Dense(256, input_dim=784))\n","model.add(Activation(\"sigmoid\"))\n","model.add(Dense(128))\n","model.add(Activation(\"sigmoid\"))\n","model.add(Dropout(rate=0.5))\n","model.add(Dense(10))\n","model.add(Activation(\"softmax\"))\n","\n","sgd = optimizers.SGD(lr=0.1) \n","model.compile(optimizer=sgd, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","model.fit(X_train, y_train, batch_size=32, epochs=5, verbose=1)\n","score = model.evaluate(X_test, y_test, verbose=0)\n","print(\"evaluate loss: {0[0]}\\nevaluate acc: {0[1]}\".format(score))\n","\n","#----------------------------"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RQumpqWnkFur","executionInfo":{"status":"ok","timestamp":1669191600145,"user_tz":-540,"elapsed":6594,"user":{"displayName":"두루미","userId":"06775262425078058900"}},"outputId":"ec04ee2a-212e-4949-f752-f37880b6d7d7"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","188/188 [==============================] - 1s 4ms/step - loss: 1.7516 - accuracy: 0.4112\n","Epoch 2/5\n","188/188 [==============================] - 1s 4ms/step - loss: 1.0546 - accuracy: 0.6623\n","Epoch 3/5\n","188/188 [==============================] - 1s 4ms/step - loss: 0.8976 - accuracy: 0.7133\n","Epoch 4/5\n","188/188 [==============================] - 1s 4ms/step - loss: 0.8314 - accuracy: 0.7412\n","Epoch 5/5\n","188/188 [==============================] - 1s 4ms/step - loss: 0.7326 - accuracy: 0.7707\n","evaluate loss: 0.6373745799064636\n","evaluate acc: 0.8299999833106995\n"]}]},{"cell_type":"code","source":["# 여기서 파이퍼파라미터 하나만 변경해서 0.85를 달성하라\n","# epoch=5 고정, 데이터 고정\n","\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","X_train = X_train.reshape(X_train.shape[0], 784)[:6000]\n","X_test = X_test.reshape(X_test.shape[0], 784)[:1000]\n","y_train = to_categorical(y_train)[:6000]\n","y_test = to_categorical(y_test)[:1000]\n","\n","# batch_size 10 -> 64\n","# 0.63 -> 0.84\n","#---------------------------\n","model = Sequential()\n","model.add(Dense(256, input_dim=784))\n","model.add(Activation(\"sigmoid\"))\n","model.add(Dense(128))\n","model.add(Activation(\"sigmoid\"))\n","model.add(Dropout(rate=0.5))\n","model.add(Dense(10))\n","model.add(Activation(\"softmax\"))\n","\n","sgd = optimizers.SGD(lr=0.1) \n","model.compile(optimizer=sgd, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","model.fit(X_train, y_train, batch_size=64, epochs=5, verbose=1)\n","score = model.evaluate(X_test, y_test, verbose=0)\n","print(\"evaluate loss: {0[0]}\\nevaluate acc: {0[1]}\".format(score))\n","\n","#----------------------------"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uvwtDmgikW2m","executionInfo":{"status":"ok","timestamp":1669191727355,"user_tz":-540,"elapsed":4021,"user":{"displayName":"두루미","userId":"06775262425078058900"}},"outputId":"b8f471ab-b949-4be6-ab69-fff0c1a55693"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","94/94 [==============================] - 1s 5ms/step - loss: 1.9017 - accuracy: 0.3572\n","Epoch 2/5\n","94/94 [==============================] - 1s 5ms/step - loss: 1.1487 - accuracy: 0.6470\n","Epoch 3/5\n","94/94 [==============================] - 1s 5ms/step - loss: 0.8772 - accuracy: 0.7402\n","Epoch 4/5\n","94/94 [==============================] - 1s 5ms/step - loss: 0.7514 - accuracy: 0.7817\n","Epoch 5/5\n","94/94 [==============================] - 0s 5ms/step - loss: 0.6755 - accuracy: 0.7963\n","evaluate loss: 0.5615936517715454\n","evaluate acc: 0.8460000157356262\n"]}]},{"cell_type":"code","source":["# 여기서 파이퍼파라미터 하나만 변경해서 0.85를 달성하라\n","# epoch=5 고정, 데이터 고정\n","\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","X_train = X_train.reshape(X_train.shape[0], 784)[:6000]\n","X_test = X_test.reshape(X_test.shape[0], 784)[:1000]\n","y_train = to_categorical(y_train)[:6000]\n","y_test = to_categorical(y_test)[:1000]\n","\n","# batch_size 10 -> 70\n","# 0.63 -> 0.86\n","#---------------------------\n","model = Sequential()\n","model.add(Dense(256, input_dim=784))\n","model.add(Activation(\"sigmoid\"))\n","model.add(Dense(128))\n","model.add(Activation(\"sigmoid\"))\n","model.add(Dropout(rate=0.5))\n","model.add(Dense(10))\n","model.add(Activation(\"softmax\"))\n","\n","sgd = optimizers.SGD(lr=0.1) \n","model.compile(optimizer=sgd, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","model.fit(X_train, y_train, batch_size=70, epochs=5, verbose=1)\n","score = model.evaluate(X_test, y_test, verbose=0)\n","print(\"evaluate loss: {0[0]}\\nevaluate acc: {0[1]}\".format(score))\n","\n","#----------------------------"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6F1JTB4cllBj","executionInfo":{"status":"ok","timestamp":1669191874489,"user_tz":-540,"elapsed":3733,"user":{"displayName":"두루미","userId":"06775262425078058900"}},"outputId":"d5b7fcab-eb4e-4f4e-950a-d726baf57052"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","86/86 [==============================] - 1s 5ms/step - loss: 1.9363 - accuracy: 0.3352\n","Epoch 2/5\n","86/86 [==============================] - 0s 5ms/step - loss: 1.1879 - accuracy: 0.6453\n","Epoch 3/5\n","86/86 [==============================] - 0s 5ms/step - loss: 0.8768 - accuracy: 0.7503\n","Epoch 4/5\n","86/86 [==============================] - 0s 5ms/step - loss: 0.7327 - accuracy: 0.7967\n","Epoch 5/5\n","86/86 [==============================] - 0s 5ms/step - loss: 0.6478 - accuracy: 0.8117\n","evaluate loss: 0.5571668148040771\n","evaluate acc: 0.8679999709129333\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"yc4sDi7QlPnU"},"execution_count":null,"outputs":[]}]}